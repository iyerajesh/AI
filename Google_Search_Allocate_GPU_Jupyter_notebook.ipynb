{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyerajesh/AI/blob/master/Google_Search_Allocate_GPU_Jupyter_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To allocate a GPU for use with a Jupyter Notebook, several steps are necessary, including setting up the environment and configuring Jupyter to utilize the GPU. Here's a general outline of the process:\n",
        "\n",
        "1.  **Install and Configure CUDA Toolkit and cuDNN:**\n",
        "    *   Install the appropriate version of the CUDA Toolkit for your GPU.\n",
        "    *   Install the cuDNN library, which is essential for accelerating deep learning tasks on NVIDIA GPUs.\n",
        "2.  **Create a Conda Environment:**\n",
        "    *   It's recommended to create a dedicated Conda environment to manage dependencies.\n",
        "    *   Use the command `conda create -n gpu_env python=<version>` to create a new environment. Replace `<version>` with your desired Python version.\n",
        "    *   Activate the environment using `conda activate gpu_env`.\n",
        "3.  **Install Required Packages:**\n",
        "    *   Install necessary packages such as `jupyter`, `tensorflow-gpu` or `torch` with CUDA support.\n",
        "    *   Use `pip install jupyter tensorflow-gpu` or the equivalent for PyTorch.\n",
        "4.  **Configure Jupyter Notebook:**\n",
        "    *   Ensure Jupyter is aware of the GPU environment. This might involve creating a new kernel that points to your Conda environment.\n",
        "5.  **Verify GPU Availability in Jupyter Notebook:**\n",
        "    *   Inside the Jupyter Notebook, use code to check if the GPU is available and being used."
      ],
      "metadata": {
        "id": "V1zQuYlc276w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2fTyCL9276z",
        "outputId": "1d87ab97-9d3d-4668-e308-c0f4b2c2d434"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "or"
      ],
      "metadata": {
        "id": "77srdXMk276z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available: \", torch.cuda.is_available())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available:  False\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_h9N8AS276z",
        "outputId": "6bee06da-a20a-4472-af71-ca3568e130d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Run Jupyter Notebook:**\n",
        "    * Launch Jupyter Notebook using the command `jupyter notebook`."
      ],
      "metadata": {
        "id": "DdprNzVa276z"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}